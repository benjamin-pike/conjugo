{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import bs4\n",
    "import lxml\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "from googletrans import Translator\n",
    "from unidecode import unidecode\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output as clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath('').replace('scripts', '')\n",
    "data_dir = os.path.join(path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nestedDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        value = self[key] = type(self)()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---HEADERS FOR WEB SCRAPING---#\n",
    "headers = {\"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "           \"accept-encoding\": \"gzip, deflate, br\",\n",
    "           \"accept-language\": \"en-GB,en;q=0.9,es-ES;q=0.8,es;q=0.7,en-US;q=0.6,eu;q=0.5\",\n",
    "           \"cache-control\": \"max-age=0\",\n",
    "           \"cookie\": \"t=238707487; _ga=GA1.2.1376835774.1641262578; _gid=GA1.2.1482423077.1641262578; _fbp=fb.1.1641262579526.851471446\",\n",
    "           \"referer\": \"https://hidemy.name/en/proxy-list/?start=64\",\n",
    "           \"sec-ch-ua-mobile\": \"?0\",\n",
    "           \"sec-ch-ua-platform\": \"macOS\",\n",
    "           \"sec-fetch-dest\": \"document\",\n",
    "           \"sec-fetch-mode\": \"navigate\",\n",
    "           \"sec-fetch-site\": \"same-origin\",\n",
    "           \"sec-fetch-user\": \"?1\",\n",
    "           \"upgrade-insecure-requests\": \"1\",\n",
    "           \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAdditionalVerbs(verb):\n",
    "\n",
    "    url = f'https://api.verbix.com/conjugator/iv1/ab8e7bb5-9ac6-11e7-ab6a-00089be4dcbc/1/3/103/{verb}'\n",
    "    page = requests.get(url, headers = headers)\n",
    "    \n",
    "    try: \n",
    "        similar_raw = re.search(r'Verbs conjugated like(.*?)<h3>', page.text).group(1)\n",
    "        similar_parsed = re.findall(r'\\\\\">(.*?)</a>', similar_raw)\n",
    "        similar_verbs = [x for x in similar_parsed if x.isalpha()]\n",
    "    except: similar_verbs = []\n",
    "\n",
    "    try: \n",
    "        prefix_raw = re.search(r'Other Verbs with Separable Prefix(.*?)<h3>', page.text).group(1)\n",
    "        prefix_parsed = re.findall(r'\\\\\">(.*?)</a>', prefix_raw)\n",
    "        prefix_verbs = [x for x in prefix_parsed if x.isalpha()]\n",
    "    except: prefix_verbs = []\n",
    "\n",
    "    try: \n",
    "        base_raw = re.search(r'Other Verbs with the same Base Verb(.*?)<h3>', page.text).group(1)\n",
    "        base_parsed = re.findall(r'\\\\\">(.*?)</a>', base_raw)\n",
    "        base_verbs = [x for x in base_parsed if x.isalpha()]\n",
    "    except: base_verbs = []\n",
    "\n",
    "    try: \n",
    "        synonyms_raw = re.search(r'<h4>Synonyms</h4>(.*?)<h3>', page.text).group(1)\n",
    "        synonyms_parsed = re.findall(r'\\\\\">(.*?)</a>', synonyms_raw)\n",
    "        synonyms_verbs = [x for x in synonyms_parsed if x.isalpha()]\n",
    "    except: synonyms_verbs = []\n",
    "\n",
    "    return list(set(similar_verbs + prefix_verbs + base_verbs + synonyms_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgramData(verb, language, years):\n",
    "    corpus = {'spanish':32, 'french':19, 'italian':22, 'german':20, }\n",
    "    syear,eyear = years\n",
    "    raw = requests.get(f'https://books.google.com/ngrams/json?content={verb}&year_start={syear}&year_end={eyear}&corpus={corpus[language]}&smoothing=0', headers = headers)\n",
    "        \n",
    "    if raw.text != '[]': data = json.loads(raw.text)[0]\n",
    "    else: return 'ngram not found'\n",
    "    \n",
    "    if data['ngram'] == verb:\n",
    "        values = data['timeseries']\n",
    "        return sum(values)/len(values)\n",
    "    else: return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRegularity(verb, page):\n",
    "\n",
    "    if 'NOTRECOGVERB' in page.text:\n",
    "        return 'x'\n",
    "    elif \"class=\\\\\\\"irregular\\\\\\\">\" in page.text:\n",
    "        return 'i'\n",
    "    elif \"class=\\\\\\\"orto\\\\\\\">\" in page.text:\n",
    "        return 'sc'\n",
    "    else:\n",
    "        return 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0f807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatResults(string):\n",
    "    \n",
    "    je = re.search(r\"(\\\\nje|\\\\nj')(.*?)(\\\\| /)\", string.text).group(2)\n",
    "    tu = re.search(r'\\\\ntu(.*?)(\\\\| /)', string.text).group(1)\n",
    "    il = re.search(r'\\\\nil;elle;on(.*?)(\\\\| /)', string.text).group(1)\n",
    "    nous = re.search(r'\\\\nnous(.*?)(\\\\| /)', string.text).group(1)\n",
    "    vous = re.search(r'\\\\nvous(.*?)(\\\\| /)', string.text).group(1)\n",
    "    ils = re.search(r'\\\\nils;elles(.*?)(\\\\| /)', string.text).group(1)\n",
    "\n",
    "    je = re.sub('[\\(].*?[\\)]', '', je).split(\";\")[0]\n",
    "    tu = re.sub('[\\(].*?[\\)]', '', tu).split(\";\")[0]\n",
    "    il = re.sub('[\\(].*?[\\)]', '', il).split(\";\")[0]\n",
    "    nous = re.sub('[\\(].*?[\\)]', '', nous).split(\";\")[0]\n",
    "    vous = re.sub('[\\(].*?[\\)]', '', vous).split(\";\")[0]\n",
    "    ils = re.sub('[\\(].*?[\\)]', '', ils).split(\";\")[0]\n",
    "\n",
    "    return [je, tu, il, nous, vous, ils]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0221f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatImperative(string, n = ''):\n",
    "\n",
    "    tu = re.search(r'\\\\ntu(.*?)(\\\\| /)', string.text).group(1)\n",
    "    nous = re.search(r'\\\\nnous(.*?)(\\\\| /)', string.text).group(1)\n",
    "    vous = re.search(r'\\\\nvous(.*?)(\\\\| /)', string.text).group(1)\n",
    "\n",
    "    tu = re.sub('[\\(].*?[\\)]', '', tu).split(\";\")[0]\n",
    "    nous = re.sub('[\\(].*?[\\)]', '', nous).split(\";\")[0]\n",
    "    vous = re.sub('[\\(].*?[\\)]', '', vous).split(\";\")[0]\n",
    "\n",
    "    firstletter = tu[0]\n",
    "\n",
    "    if n:\n",
    "        if [x for x in ['a', 'e', 'i', 'o', 'u'] if x == firstletter]:\n",
    "            tu = f\"n'{tu} pas\"\n",
    "            nous = f\"n'{nous} pas\"\n",
    "            vous = f\"n'{vous} pas\"\n",
    "        else:\n",
    "            tu = f\"ne {tu} pas\"\n",
    "            nous = f\"ne {nous} pas\"\n",
    "            vous = f\"ne {vous} pas\"\n",
    "\n",
    "    if 'notused' not in str(string):\n",
    "        return [tu, nous, vous]\n",
    "    else:\n",
    "        return ['', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SCRAPE REVERSO FOR TRANSLATIONS---#\n",
    "def getReversoTranslations(verb):\n",
    "\n",
    "    translations = []\n",
    "\n",
    "    page = requests.get(f'https://context.reverso.net/translation/french-english/{verb}', headers = headers)\n",
    "    soup = bs4.BeautifulSoup(page.text)\n",
    "\n",
    "    if verb in soup.select('title')[0].getText():\n",
    "\n",
    "        while len(soup.find_all('div', {\"class\": \"mobile-hidden\"})) > 0:\n",
    "            soup.find_all('div', {\"class\": \"mobile-hidden\"})[0].extract()\n",
    "        \n",
    "        while len(soup.find_all('a', {\"class\": \"mobile-hidden\"})) > 0:  \n",
    "            soup.find_all('a', {\"class\": \"mobile-hidden\"})[0].extract()\n",
    "\n",
    "        for i in range(0, len(soup.select('#translations-content .translation.ltr.dict.v'))):\n",
    "            entry = soup.select('#translations-content .translation.ltr.dict.v')[i].getText().replace('\\n\\n\\n\\r\\n          ','').replace('\\n','')\n",
    "            \n",
    "            if entry.replace(' ','').isalpha() and entry not in translations:\n",
    "                translations.append(entry)\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---USE GOOGLETRANS PACKAGE TO FIND TRANSLATONS---#\n",
    "def getGoogleTranslations(verb):\n",
    "    \n",
    "    try: \n",
    "        translations = translator.translate(verb, dest = 'en', src = 'fr').extra_data['all-translations']\n",
    "\n",
    "        if translations != None:\n",
    "            for x in range(0, len(translations)):\n",
    "                if translations[x][0] == 'verb':\n",
    "                    translations = translations[x][1]\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            translations = []\n",
    "                    \n",
    "    except Exception as ex:\n",
    "            translations = []\n",
    "    \n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c44345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate(verb_data):\n",
    "    \n",
    "    verb,rank = verb_data\n",
    "\n",
    "    url = f'https://api.verbix.com/conjugator/iv1/ab8e7bb5-9ac6-11e7-ab6a-00089be4dcbc/1/3/103/{verb}'\n",
    "    page = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(page.text, 'lxml') \n",
    "\n",
    "    if rank < 50000:\n",
    "\n",
    "        dictionary = nestedDict()\n",
    "\n",
    "        dictionary['infinitive'] = verb\n",
    "        dictionary['rank'] = rank\n",
    "        dictionary['regularity'] = checkRegularity(verb, page)\n",
    "\n",
    "        dictionary['translations'] = []\n",
    "\n",
    "        dictionary['participle'] = {'present': re.search(r'Participe présent:\\\\r\\\\n(.*?)(\\\\| /)', soup.select('body')[0].getText()).group(1).lstrip(),\n",
    "                                    'past': re.search(r'Participe passé\\\\r\\\\n (.*?)(\\\\| /)', soup.select('body')[0].getText()).group(1).lstrip()}\n",
    "\n",
    "        subjects_indicies = [0, 1, 2, 2, 2, 3, 4, 5, 5]\n",
    "        subjects_pronouns = ['je', 'tu', 'il', 'elle', 'ons', 'nous', 'vous', 'ils', 'elles']\n",
    "\n",
    "        subjects_indicies_imp = [0, 1, 2]\n",
    "        subjects_pronouns_imp = ['tu', 'nous', 'vous']\n",
    "\n",
    "        for i,p in zip(subjects_indicies, subjects_pronouns):\n",
    "\n",
    "            #indicative\n",
    "            dictionary['simple']['indicative']['present'][p] = formatResults(soup.select('table')[0])[i]\n",
    "            dictionary['simple']['indicative']['preterite'][p] = formatResults(soup.select('table')[6])[i]\n",
    "            dictionary['simple']['indicative']['imperfect'][p] = formatResults(soup.select('table')[2])[i]\n",
    "            dictionary['simple']['indicative']['conditional'][p] = formatResults(soup.select('table')[12])[i]\n",
    "            dictionary['simple']['indicative']['future'][p] = formatResults(soup.select('table')[4])[i]\n",
    "\n",
    "            #subjunctive\n",
    "            dictionary['simple']['subjunctive']['present'][p] = formatResults(soup.select('table')[8])[i]\n",
    "            dictionary['simple']['subjunctive']['imperfect'][p] = formatResults(soup.select('table')[10])[i]\n",
    "\n",
    "            #perfect indicative\n",
    "            dictionary['compound']['indicative']['present'][p] = formatResults(soup.select('table')[1])[i]\n",
    "            dictionary['compound']['indicative']['preterite'][p] = formatResults(soup.select('table')[7])[i]\n",
    "            dictionary['compound']['indicative']['imperfect'][p] = formatResults(soup.select('table')[3])[i]\n",
    "            dictionary['compound']['indicative']['conditional'][p] = formatResults(soup.select('table')[13])[i]\n",
    "            dictionary['compound']['indicative']['future'][p] = formatResults(soup.select('table')[5])[i]\n",
    "\n",
    "            #perfect subjunctive\n",
    "            dictionary['compound']['subjunctive']['present'][p] = formatResults(soup.select('table')[9])[i]\n",
    "            dictionary['compound']['subjunctive']['imperfect'][p] = formatResults(soup.select('table')[11])[i]\n",
    "\n",
    "        #imperative\n",
    "            try:\n",
    "                for i,p in zip(subjects_indicies_imp, subjects_pronouns_imp):\n",
    "                    dictionary['simple']['imperative']['affirmative'][p] = formatImperative(soup.select('table')[14])[i]\n",
    "                    dictionary['simple']['imperative']['negative'][p] = formatImperative(soup.select('table')[14], 'negative')[i]\n",
    "            except:\n",
    "                for i,p in zip(subjects_indicies_imp, subjects_pronouns_imp):\n",
    "                    dictionary['simple']['imperative']['affirmative'][p] = ''\n",
    "                    dictionary['simple']['imperative']['negative'][p] = ''\n",
    "    \n",
    "        return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SCRAPE UNRANKED VERBS FROM COOLJUGATOR---#\n",
    "page = requests.get('https://cooljugator.com/fr/list/all', headers = headers)\n",
    "soup = bs4.BeautifulSoup(page.text, 'lxml')\n",
    "coolverbs = []\n",
    "\n",
    "for item in soup.select('.ui.segment.stacked .item'):\n",
    "    verb = item.getText().split(' ')[0]\n",
    "    if len(item.getText().split(' ')) == 3 and verb.isalpha() and (verb[-1] == 'r' or verb[-2:] == 're'):\n",
    "        coolverbs.append(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SCRAPE UNRANKED VERBS FROM WIKIPEDIA---#\n",
    "wikiverbs = []\n",
    "urlsafe = set([x for x in 'abcdefghijklmnopqrstuvwxyz'])\n",
    "last = 'abader'\n",
    "run = True\n",
    "\n",
    "while run:\n",
    "\n",
    "    url = f'https://en.wiktionary.org/w/index.php?title=Category:French_verbs&pagefrom={last}'\n",
    "    page = requests.get(url, headers = headers)\n",
    "    soup = bs4.BeautifulSoup(page.text, 'lxml') \n",
    "    list_items = soup.select('.mw-content-ltr .mw-category li a')\n",
    "\n",
    "    for i in range(18, len(list_items)):\n",
    "        verb = list_items[i].getText()\n",
    "\n",
    "        if verb not in wikiverbs and ' ' not in verb and verb.isalpha() and (verb[-1] == 'r' or verb[-2:] == 're'):\n",
    "            wikiverbs.append(verb.lower())\n",
    "            clear(wait = True); print(wikiverbs[-1])\n",
    "    \n",
    "    for verb in reversed(wikiverbs):\n",
    "        split = set([x for x in verb])  \n",
    "\n",
    "        if len(split - urlsafe) == 0:\n",
    "            if verb == 'avoir':\n",
    "                last = 'avoisiner'; break\n",
    "            elif verb == 'faire':\n",
    "                last = 'falloir'; break\n",
    "            elif verb != last:\n",
    "                last = verb; break\n",
    "            else:\n",
    "                run = False\n",
    "\n",
    "        elif verb.isalpha():\n",
    "            if unidecode(verb) != last:\n",
    "                last = unidecode(verb); break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---COMBINE VERBS FROM COOLJUGATOR AND WIKIPEDIA---#\n",
    "all_verbs = list(set(coolverbs + wikiverbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---FIND ADDITIONAL VERBS USING VERBIX---#\n",
    "total = all_verbs\n",
    "new_verbs = []\n",
    "initlen = len(all_verbs)\n",
    "\n",
    "for i in range(0, len(all_verbs)):\n",
    "    \n",
    "    additional = findAdditionalVerbs(all_verbs[i])\n",
    "    \n",
    "    for verb in additional:\n",
    "        if verb not in total:\n",
    "            total.append(verb)\n",
    "            new_verbs.append(verb)\n",
    "    \n",
    "    clear(wait = True); print(f\"{all_verbs[i]} – {initlen} -> {len(total)} | {len(new_verbs)} ({round(i*100/initlen, 3)}%)\")\n",
    "\n",
    "all_verbs = total; del total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SET VARIABLES FOR NGRAM SCORES---#\n",
    "verbs = []\n",
    "infinitives = []\n",
    "rank = 1\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---ITERATE THROUGH ALL VERBS AND FIND NGRAM SCORES---#\n",
    "while i < len(all_verbs):\n",
    "    try:\n",
    "        verb = all_verbs[i]\n",
    "        value = getNgramData(verb, 'french', (1980, 2005))\n",
    "\n",
    "        if isinstance(value, float):\n",
    "            verbs.append([verb, value])\n",
    "            clear(wait = True); print(f\"{verbs[-1]} ({round(i*100/len(all_verbs), 3)}%)\")\n",
    "        \n",
    "        i += 1; time.sleep(1)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        clear(wait = True); print(f\"error ({ex}) – sleeping for 2 minutes ({round(i*100/len(all_verbs), 3)}%)\")\n",
    "        time.sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---RANK VERBS ACCORDING TO NGRAM SCORES---#\n",
    "for verb in sorted(verbs, key = lambda x: x[1])[::-1]:\n",
    "    infinitives.append([verb[0], rank])\n",
    "    rank += 1\n",
    "\n",
    "verbs = infinitives; del infinitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---FILTER DUPLICATES AND RERANK VERBS---#\n",
    "decoded = []\n",
    "unique = []\n",
    "rank = 1\n",
    "\n",
    "for verb in verbs:\n",
    "    if unidecode(verb[0]) not in decoded:\n",
    "        decoded.append(unidecode(verb[0]))\n",
    "        unique.append([verb[0], rank])\n",
    "        rank += 1\n",
    "\n",
    "print(f\"{len(verbs)} -> {len(unique)}\")\n",
    "infinitives = unique; del unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---CREATE INTERMEDIATE CHECKPOINT FILE AS CONTINGENCY IN CASE OF KERNAL TIMEOUT---#\n",
    "f = os.path.join(data_dir, 'infinitives_french_intermediate.json')\n",
    "\n",
    "with open(f, \"w\", encoding = 'utf8') as file:\n",
    "    json.dump(infinitives, file, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---OPEN CHECKPOINT FILE---#\n",
    "f = os.path.join(data_dir, 'infinitives_french_intermediate.json')\n",
    "\n",
    "with open(f, \"r\", encoding = 'utf8') as file:\n",
    "    infinitives = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SET VARIABLES FOR CONJUGATIONS---#\n",
    "conjugations = defaultdict()\n",
    "defective = set()\n",
    "skipped = []\n",
    "rank = 1\n",
    "exclude = ['avenir', 'étranger', 'hier', 'leader', 'dealer', 'perler', 'recoder', 'jogger', 'rapper', 'purer', \n",
    "           'extasier', 'reposter' 'recorder', 'valdinguer', 'défriser', 'baller', 'effiler', 'dinguer', 'débâtir', \n",
    "           'remélanger', 'bloguer', 'messeoir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SET INDEX AT WHICH TO START CONJUGATIONS---#\n",
    "start = 4516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---GENERATE CONJUGATIONS---#\n",
    "for i in range(start, len(infinitives)):\n",
    "    infinitive = infinitives[i]\n",
    "\n",
    "    try:\n",
    "        c = conjugate(infinitive)\n",
    "\n",
    "        if c != None and infinitive[0] not in exclude: \n",
    "            conjugations[c['infinitive']] = c\n",
    "            conjugations[infinitive[0]]['rank'] = rank\n",
    "            rank += 1\n",
    "\n",
    "            clear(wait = True), print(f\"{infinitive[0]} – complete ({round(i*100/len(infinitives), 3)}%)\")\n",
    "        \n",
    "        else:\n",
    "            clear(wait = True), print(f\"{infinitive[0]} – skipped ({round(i*100/len(infinitives), 3)}%)\")\n",
    "            skipped.append(infinitive)\n",
    "\n",
    "    except Exception as ex:\n",
    "        clear(wait = True), print(f\"{infinitive[0]} – skipped – {ex} ({round(i*100/len(infinitives), 3)}%)\")\n",
    "        skipped.append(infinitive)\n",
    "\n",
    "conjugations = dict(conjugations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---REMOVE VERBS WITH UNKNOWN OR CONFLICTING REGULARITIES---#\n",
    "remove = []\n",
    "rank = 1\n",
    "\n",
    "for verb in conjugations:\n",
    "    if conjugations[verb]['regularity'] == 'x':\n",
    "        remove.append(verb)\n",
    "    else:\n",
    "        conjugations[verb]['rank'] = rank\n",
    "        rank += 1\n",
    "\n",
    "print(f\"{len(infinitives)} -> {len(infinitives) - len(remove)}\")\n",
    "\n",
    "for verb in remove:\n",
    "    conjugations.pop[verb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---CREATE INTERMEDIATE CHECKPOINT FILE AS CONTINGENCY IN CASE OF KERNAL TIMEOUT---#\n",
    "with open(os.path.join(data_dir, 'conjugations_french_intermediate.json'), \"w\", encoding = 'utf8') as file:\n",
    "    json.dump(conjugations, file, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SET INDEX VARIABLE TO 1 BY DEFAULT---#\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---OPEN CHECKPOINT FILE---#\n",
    "with open(os.path.join(data_dir, 'conjugations_translated_french_intermediate.json'), \"r\", encoding = 'utf8') as file:\n",
    "    conjugations = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quimper (6656) – complete (68.043%)\n"
     ]
    }
   ],
   "source": [
    "#---ADD TRANSLATIONS---#\n",
    "for verb in conjugations:\n",
    "\n",
    "    if conjugations[verb]['rank'] > i - 1 and conjugations[verb]['translations'] == []:\n",
    "        \n",
    "        translations = getReversoTranslations(verb)\n",
    "\n",
    "        if not translations:\n",
    "            translations = getGoogleTranslations(verb)\n",
    "            time.sleep(9)\n",
    "\n",
    "        conjugations[verb]['translations'] = translations\n",
    "\n",
    "        if conjugations[verb]['rank'] % 200 == 0:\n",
    "            with open(os.path.join(data_dir, 'conjugations_translated_french_intermediate.json'), \"w\", encoding = 'utf8') as file:\n",
    "                json.dump(conjugations, file, indent = 4, ensure_ascii = False)\n",
    "\n",
    "        clear(wait = True), print(f\"{verb} ({i}) – complete ({round(i*100/len(conjugations), 3)}%)\")\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---REMOVE VERBS WITH NO TRANSLATIONS---#\n",
    "remove = []\n",
    "rank = 1\n",
    "\n",
    "for verb in conjugations:\n",
    "    if conjugations[verb]['translations'] == []:\n",
    "        remove.append(verb)\n",
    "    else:\n",
    "        conjugations[verb]['rank'] = rank\n",
    "        rank += 1\n",
    "\n",
    "for verb in remove:\n",
    "    conjugations.pop(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SAVE TO JSON---#\n",
    "f = os.path.join(data_dir, 'conjugations_french.json')\n",
    "with open(f, \"w\", encoding = 'utf8') as file:\n",
    "    json.dump(conjugations, file, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---PARSE INFINITIVES AND SAVE TO JSON---#\n",
    "infinitives = []\n",
    "\n",
    "for verb in conjugations:\n",
    "    infinitives.append([verb, conjugations[verb]['rank'], conjugations[verb]['regularity']])\n",
    "\n",
    "f = os.path.join(data_dir, 'infinitives_french.json')\n",
    "with open(f, \"w\", encoding = 'utf8') as file:\n",
    "    json.dump(infinitives, file, indent = 4, ensure_ascii = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9596ba951ddb21d01b6d37648fb60066e40c7f4a0a12dddda8d43c6adacb1362"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
