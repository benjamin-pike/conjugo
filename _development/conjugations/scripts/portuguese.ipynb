{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import bs4\n",
    "import lxml\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "from googletrans import Translator\n",
    "from unidecode import unidecode\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output as clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath('').replace('scripts', '')\n",
    "data_dir = os.path.join(path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nestedDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        value = self[key] = type(self)()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---HEADERS FOR WEB SCRAPING---#\n",
    "headers = {\"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "           \"accept-encoding\": \"gzip, deflate, br\",\n",
    "           \"accept-language\": \"en-GB,en;q=0.9,es-ES;q=0.8,es;q=0.7,en-US;q=0.6,eu;q=0.5\",\n",
    "           \"cache-control\": \"max-age=0\",\n",
    "           \"cookie\": \"t=238707487; _ga=GA1.2.1376835774.1641262578; _gid=GA1.2.1482423077.1641262578; _fbp=fb.1.1641262579526.851471446\",\n",
    "           \"referer\": \"https://hidemy.name/en/proxy-list/?start=64\",\n",
    "           \"sec-ch-ua-mobile\": \"?0\",\n",
    "           \"sec-ch-ua-platform\": \"macOS\",\n",
    "           \"sec-fetch-dest\": \"document\",\n",
    "           \"sec-fetch-mode\": \"navigate\",\n",
    "           \"sec-fetch-site\": \"same-origin\",\n",
    "           \"sec-fetch-user\": \"?1\",\n",
    "           \"upgrade-insecure-requests\": \"1\",\n",
    "           \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAdditionalVerbs(verb):\n",
    "\n",
    "    url = f'https://api.verbix.com/conjugator/iv1/ab8e7bb5-9ac6-11e7-ab6a-00089be4dcbc/1/2/102/{verb}'\n",
    "    page = requests.get(url, headers = headers)\n",
    "    \n",
    "    try: \n",
    "        similar_raw = re.search(r'Verbs conjugated like(.*?)<h3>', page.text).group(1)\n",
    "        similar_parsed = re.findall(r'\\\\\">(.*?)</a>', similar_raw)\n",
    "        similar_verbs = [x for x in similar_parsed if x.isalpha()]\n",
    "    except: similar_verbs = []\n",
    "\n",
    "    try: \n",
    "        prefix_raw = re.search(r'Other Verbs with Separable Prefix(.*?)<h3>', page.text).group(1)\n",
    "        prefix_parsed = re.findall(r'\\\\\">(.*?)</a>', prefix_raw)\n",
    "        prefix_verbs = [x for x in prefix_parsed if x.isalpha()]\n",
    "    except: prefix_verbs = []\n",
    "\n",
    "    try: \n",
    "        base_raw = re.search(r'Other Verbs with the same Base Verb(.*?)<h3>', page.text).group(1)\n",
    "        base_parsed = re.findall(r'\\\\\">(.*?)</a>', base_raw)\n",
    "        base_verbs = [x for x in base_parsed if x.isalpha()]\n",
    "    except: base_verbs = []\n",
    "\n",
    "    try: \n",
    "        synonyms_raw = re.search(r'<h4>Synonyms</h4>(.*?)<h3>', page.text).group(1)\n",
    "        synonyms_parsed = re.findall(r'\\\\\">(.*?)</a>', synonyms_raw)\n",
    "        synonyms_verbs = [x for x in synonyms_parsed if x.isalpha()]\n",
    "    except: synonyms_verbs = []\n",
    "\n",
    "    return list(set(similar_verbs + prefix_verbs + base_verbs + synonyms_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRegularity(verb, page):\n",
    "\n",
    "    if 'NOTRECOGVERB' in page.text:\n",
    "        return 'x'\n",
    "    elif \"class=\\\\\\\"irregular\\\\\\\">\" in page.text:\n",
    "        return 'i'\n",
    "    elif \"class=\\\\\\\"orto\\\\\\\">\" in page.text:\n",
    "        return 'sc'\n",
    "    else:\n",
    "        return 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatResults(string, participle = ''):\n",
    "    pre = 0\n",
    "    suf = ''\n",
    "\n",
    "    for p in ['que', 'se', 'quando']:\n",
    "        if string.select('li')[0].getText()[:len(p) + 2] == p + 'eu':\n",
    "            pre = len(p)\n",
    "    \n",
    "    if participle:\n",
    "        suf = ' ' + participle\n",
    "\n",
    "    eu = string.select('li')[0].getText()[pre + 2:][::-1][len(participle):][::-1] + suf\n",
    "    tu = string.select('li')[1].getText()[pre + 2:][::-1][len(participle):][::-1] + suf\n",
    "    ele = string.select('li')[2].getText()[pre + 12:][::-1][len(participle):][::-1] + suf\n",
    "    nos = string.select('li')[3].getText()[pre + 3:][::-1][len(participle):][::-1] + suf\n",
    "    vos = string.select('li')[4].getText()[pre + 3:][::-1][len(participle):][::-1] + suf\n",
    "    eles = string.select('li')[5].getText()[pre + 15:][::-1][len(participle):][::-1] + suf\n",
    "\n",
    "    return [eu, tu, ele, nos, vos, eles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f27938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEstar():\n",
    "    url = 'https://conjugator.reverso.net/conjugation-portuguese-verb-estar.html'\n",
    "    page = requests.get(url, headers = headers)\n",
    "    soup = bs4.BeautifulSoup(page.text, 'lxml') \n",
    "\n",
    "    dictionary = nestedDict()\n",
    "\n",
    "    subjects_indicies = [0, 1, 2, 2, 2, 3, 4, 5, 5, 5]\n",
    "    subjects_pronouns = ['eu', 'tu', 'ele', 'ela', 'você', 'nós', 'vós', 'eles', 'elas', 'vocês']\n",
    "    \n",
    "    for i,p in zip(subjects_indicies, subjects_pronouns):\n",
    "        dictionary['present'][p] = formatResults(soup.select('.blue-box-wrap')[0])[i]\n",
    "        dictionary['preterite'][p] = formatResults(soup.select('.blue-box-wrap')[1])[i]\n",
    "        dictionary['imperfect'][p] = formatResults(soup.select('.blue-box-wrap')[2])[i]\n",
    "        dictionary['future'][p] = formatResults(soup.select('.blue-box-wrap')[7])[i]\n",
    "        dictionary['conditional'][p] = formatResults(soup.select('.blue-box-wrap')[15])[i]\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatImperative(string, negative = ''):\n",
    "    if negative:\n",
    "        pre = 'não '\n",
    "    else:\n",
    "        pre = ' '\n",
    "    tu = pre.lstrip() + string.select('li')[0].getText()[len(pre) - 1:]\n",
    "    voce = pre.lstrip() + string.select('li')[1].getText()[len(pre) - 1:]\n",
    "    nos = pre.lstrip() + string.select('li')[2].getText()[len(pre) - 1:]\n",
    "    vos = pre.lstrip() + string.select('li')[3].getText()[len(pre) - 1:]\n",
    "    voces  = pre.lstrip() + string.select('li')[4].getText()[len(pre) - 1:]\n",
    "\n",
    "    return [tu, voce, nos, vos, voces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SCRAPE REVERSO FOR TRANSLATIONS---#\n",
    "def getReversoTranslations(verb):\n",
    "\n",
    "    translations = []\n",
    "\n",
    "    page = requests.get(f'https://context.reverso.net/translation/portuguese-english/{verb}', headers = headers)\n",
    "    soup = bs4.BeautifulSoup(page.text)\n",
    "\n",
    "    if verb in soup.select('title')[0].getText():\n",
    "\n",
    "        while len(soup.find_all('div', {\"class\": \"mobile-hidden\"})) > 0:\n",
    "            soup.find_all('div', {\"class\": \"mobile-hidden\"})[0].extract()\n",
    "        \n",
    "        while len(soup.find_all('a', {\"class\": \"mobile-hidden\"})) > 0:  \n",
    "            soup.find_all('a', {\"class\": \"mobile-hidden\"})[0].extract()\n",
    "\n",
    "        for i in range(0, len(soup.select('#translations-content .translation.ltr.dict.v'))):\n",
    "            translations.append(soup.select('#translations-content .translation.ltr.dict.v')[i].getText().replace('\\n\\n\\n\\r\\n          ','').replace('\\n',''))\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---USE GOOGLETRANS PACKAGE TO FIND TRANSLATONS---#\n",
    "def getGoogleTranslations(verb):\n",
    "    \n",
    "    try: \n",
    "        translations = translator.translate(verb, dest = 'en', src = 'pt').extra_data['all-translations']\n",
    "\n",
    "        if translations != None:\n",
    "            for x in range(0, len(translations)):\n",
    "                if translations[x][0] == 'verb':\n",
    "                    translations = translations[x][1]\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            translations = []\n",
    "                    \n",
    "    except Exception as ex:\n",
    "            translations = []\n",
    "    \n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate(verb_data):\n",
    "    \n",
    "    verb,rank = verb_data\n",
    "\n",
    "    url = f'https://conjugator.reverso.net/conjugation-portuguese-verb-{verb}.html'\n",
    "    page = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "    verbix_page = requests.get(f'https://api.verbix.com/conjugator/iv1/ab8e7bb5-9ac6-11e7-ab6a-00089be4dcbc/1/2/102/{verb}')\n",
    "\n",
    "    if rank < 50000:\n",
    "\n",
    "        dictionary = nestedDict()\n",
    "\n",
    "        dictionary['infinitive'] = verb\n",
    "        dictionary['rank'] = rank\n",
    "        dictionary['regularity'] = checkRegularity(verb, verbix_page)\n",
    "\n",
    "        dictionary['translations'] = []\n",
    "\n",
    "        dictionary['participle'] = {'present': soup.select('.blue-box-wrap')[17].getText(),\n",
    "                                    'past': soup.select('.blue-box-wrap')[21].getText()}\n",
    "\n",
    "        subjects_indicies = [0, 1, 2, 2, 2, 3, 4, 5, 5, 5]\n",
    "        subjects_pronouns = ['eu', 'tu', 'ele', 'ela', 'você', 'nós', 'vós', 'eles', 'elas', 'vocês']\n",
    "\n",
    "        subjects_indicies_imp = [0, 1, 2, 3, 4]\n",
    "        subjects_pronouns_imp = ['tu', 'você', 'nós', 'vós', 'vocês']\n",
    "\n",
    "        for i,p in zip(subjects_indicies, subjects_pronouns):\n",
    "\n",
    "            #Simple\n",
    "            dictionary['simple']['indicative']['present'][p] = formatResults(soup.select('.blue-box-wrap')[0])[i]\n",
    "            dictionary['simple']['indicative']['preterite'][p] = formatResults(soup.select('.blue-box-wrap')[1])[i]\n",
    "            dictionary['simple']['indicative']['imperfect'][p] = formatResults(soup.select('.blue-box-wrap')[2])[i]\n",
    "            dictionary['simple']['indicative']['pluperfect'][p] = formatResults(soup.select('.blue-box-wrap')[3])[i]\n",
    "            dictionary['simple']['indicative']['future'][p] = formatResults(soup.select('.blue-box-wrap')[7])[i]\n",
    "\n",
    "            dictionary['simple']['subjunctive']['present'][p] = formatResults(soup.select('.blue-box-wrap')[9])[i]\n",
    "            dictionary['simple']['subjunctive']['imperfect'][p] = formatResults(soup.select('.blue-box-wrap')[11])[i]\n",
    "            dictionary['simple']['subjunctive']['future'][p] = formatResults(soup.select('.blue-box-wrap')[13])[i]\n",
    "\n",
    "            dictionary['simple']['conditional']['conditional'][p] = formatResults(soup.select('.blue-box-wrap')[15])[i]\n",
    "\n",
    "            #perfect indicative\n",
    "            dictionary['compound']['indicative']['present'][p] = formatResults(soup.select('.blue-box-wrap')[4], dictionary['participle']['past'])[i]\n",
    "            dictionary['compound']['indicative']['imperfect'][p] = formatResults(soup.select('.blue-box-wrap')[5], dictionary['participle']['past'])[i]\n",
    "            dictionary['compound']['indicative']['future'][p] = formatResults(soup.select('.blue-box-wrap')[8], dictionary['participle']['past'])[i]\n",
    "\n",
    "            #perfect subjunctive\n",
    "            dictionary['compound']['subjunctive']['present'][p] = formatResults(soup.select('.blue-box-wrap')[10], dictionary['participle']['past'])[i]\n",
    "            dictionary['compound']['subjunctive']['imperfect'][p] = formatResults(soup.select('.blue-box-wrap')[12], dictionary['participle']['past'])[i]\n",
    "            dictionary['compound']['subjunctive']['future'][p] = formatResults(soup.select('.blue-box-wrap')[14], dictionary['participle']['past'])[i]\n",
    "\n",
    "            dictionary['compound']['conditional']['conditional'][p] = formatResults(soup.select('.blue-box-wrap')[16], dictionary['participle']['past'])[i]\n",
    "\n",
    "            #progressive\n",
    "            dictionary['progressive']['indicative']['present'][p] = f\"{estar['present'][p]} {dictionary['participle']['present']}\"\n",
    "            dictionary['progressive']['indicative']['preterite'][p] = f\"{estar['preterite'][p]} {dictionary['participle']['present']}\"\n",
    "            dictionary['progressive']['indicative']['imperfect'][p] = f\"{estar['imperfect'][p]} {dictionary['participle']['present']}\"\n",
    "            dictionary['progressive']['indicative']['future'][p] = f\"{estar['future'][p]} {dictionary['participle']['present']}\"\n",
    "            \n",
    "            dictionary['progressive']['conditional']['conditional'][p] = f\"{estar['conditional'][p]} {dictionary['participle']['present']}\"\n",
    "        \n",
    "        #imperative\n",
    "        try:\n",
    "            for i,p in zip(subjects_indicies_imp, subjects_pronouns_imp):\n",
    "                dictionary['simple']['imperative']['affirmative'][p] = formatImperative(soup.select('.blue-box-wrap')[19])[i]\n",
    "                dictionary['simple']['imperative']['negative'][p] = formatImperative(soup.select('.blue-box-wrap')[20], 'negative')[i]\n",
    "        except:\n",
    "            for i,p in zip(subjects_indicies_imp, subjects_pronouns_imp):\n",
    "                dictionary['simple']['imperative']['affirmative'][p] = ''\n",
    "                dictionary['simple']['imperative']['negative'][p] = ''\n",
    "    \n",
    "        return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SCRAPE UNRANKED VERBS FROM COOLJUGATOR---#\n",
    "page = requests.get('https://cooljugator.com/pt/list/all', headers = headers)\n",
    "soup = bs4.BeautifulSoup(page.text, 'lxml')\n",
    "coolverbs = []\n",
    "\n",
    "for item in soup.select('.ui.segment.stacked .item'):\n",
    "    verb = item.getText().split(' ')[0]\n",
    "    if len(item.getText().split(' ')) == 3 and verb.isalpha() and (verb[-1] == 'r' or verb[-2:] == 'se'):\n",
    "        coolverbs.append(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SCRAPE UNRANKED VERBS FROM WIKIPEDIA---#\n",
    "wikiverbs = []\n",
    "urlsafe = set([x for x in 'abcdefghijklmnopqrstuvwxyz'])\n",
    "last = 'abacharelar'\n",
    "run = True\n",
    "\n",
    "while run:\n",
    "\n",
    "    url = f'https://en.wiktionary.org/w/index.php?title=Category:Portuguese_verbs&pagefrom={last}'\n",
    "    page = requests.get(url, headers = headers)\n",
    "    soup = bs4.BeautifulSoup(page.text, 'lxml') \n",
    "    list_items = soup.select('.mw-content-ltr .mw-category li a')\n",
    "\n",
    "    for i in range(18, len(list_items)):\n",
    "        verb = list_items[i].getText()\n",
    "\n",
    "        if verb not in wikiverbs and ' ' not in verb and verb.isalpha() and (verb[-1] == 'r' or verb[-2:] == 'se'):\n",
    "            wikiverbs.append(verb.lower())\n",
    "            clear(); print(wikiverbs[-1])\n",
    "    \n",
    "    for verb in reversed(wikiverbs):\n",
    "        split = set([x for x in verb])  \n",
    "        if len(split - urlsafe) == 0:\n",
    "            if verb != last:\n",
    "                last = verb\n",
    "                break\n",
    "            else:\n",
    "                run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---COMBINE VERBS FROM COOLJUGATOR AND WIKIPEDIA---#\n",
    "all_verbs = list(set(coolverbs + wikiverbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---FIND ADDITIONAL VERBS USING VERBIX---#\n",
    "total = all_verbs\n",
    "new_verbs = []\n",
    "initlen = len(all_verbs)\n",
    "\n",
    "for i in range(0, len(all_verbs)):\n",
    "    \n",
    "    additional = findAdditionalVerbs(all_verbs[i])\n",
    "    \n",
    "    for verb in additional:\n",
    "        if verb not in total:\n",
    "            total.append(verb)\n",
    "            new_verbs.append(verb)\n",
    "    \n",
    "    clear(wait = True); print(f\"{all_verbs[i]} – {initlen} -> {len(total)} | {len(new_verbs)} ({round(i*100/initlen, 3)}%)\")\n",
    "\n",
    "all_verbs = total; del total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---ITERATE THROUGH ALL VERBS AND RANK ACCORDING TO FREQUENCY---#\n",
    "infinitives = []\n",
    "rank = 1\n",
    "i = 0\n",
    "\n",
    "with open(\"../frequency/portuguese.txt\") as file:\n",
    "    frequency_list = file.read().split('\\n')\n",
    "\n",
    "for i in range(0, len(frequency_list)):\n",
    "\n",
    "    entry = frequency_list[i].split(' ')[0]\n",
    "\n",
    "    if len(entry) > 1 and (entry[-1] == 'r' or entry[-2:] == 'se'):\n",
    "        if entry in all_verbs and entry not in infinitives and entry != 'por':\n",
    "            infinitives.append([entry, rank])\n",
    "            rank += 1\n",
    "\n",
    "            clear(wait = True); print(f\"{entry} | {len(infinitives)} ({round(i*100/len(frequency_list), 3)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---FILTER DUPLICATES AND RERANK VERBS---#\n",
    "decoded = []\n",
    "unique = []\n",
    "rank = 1\n",
    "\n",
    "for verb in infinitives:\n",
    "    if unidecode(verb[0]) not in decoded:\n",
    "        decoded.append(unidecode(verb[0]))\n",
    "        unique.append([verb[0], rank])\n",
    "        rank += 1\n",
    "\n",
    "print(f\"{len(infinitives)} -> {len(unique)}\")\n",
    "\n",
    "infinitives = unique; del unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---CREATE INTERMEDIATE CHECKPOINT FILE AS CONTINGENCY IN CASE OF KERNAL TIMEOUT---#\n",
    "f = os.path.join(data_dir, 'infinitives_portuguese_intermediate.json')\n",
    "\n",
    "with open(f, \"w\", encoding = 'utf8') as file:\n",
    "    json.dump(infinitives, file, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---OPEN CHECKPOINT FILE---#\n",
    "f = os.path.join(data_dir, 'language-specific', 'infinitives_portuguese.json')\n",
    "\n",
    "with open(f, \"r\", encoding = 'utf8') as file:\n",
    "    infinitives = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SET VARIABLES FOR CONJUGATIONS---#\n",
    "estar = getEstar()\n",
    "conjugations = defaultdict()\n",
    "defective = set()\n",
    "skipped = []\n",
    "rank = 1\n",
    "exclude = ['por']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SET INDEX AT WHICH TO START CONJUGATIONS---#\n",
    "start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---GENERATE CONJUGATIONS---#\n",
    "for i in range(start, len(infinitives)):\n",
    "\n",
    "    infinitive = infinitives[i]\n",
    "    try:\n",
    "        c = conjugate(infinitive)\n",
    "\n",
    "        if c != None and infinitive[0] not in exclude: \n",
    "            conjugations[c['infinitive']] = c\n",
    "            conjugations[infinitive[0]]['rank'] = rank\n",
    "            rank += 1\n",
    "\n",
    "            clear(wait = True), print(f\"{infinitive[0]} – complete ({round(i*100/len(infinitives), 3)}%)\")\n",
    "        \n",
    "        else:\n",
    "            clear(wait = True), print(f\"{infinitive[0]} – skipped ({round(i*100/len(infinitives), 3)}%)\")\n",
    "            skipped.append(infinitive)\n",
    "\n",
    "    except Exception as ex:\n",
    "        clear(wait = True), print(f\"{infinitive[0]} – skipped – {ex} ({round(i*100/len(infinitives), 3)}%)\")\n",
    "        skipped.append(infinitive)\n",
    "\n",
    "conjugations = dict(conjugations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---REMOVE VERBS WITH UNKNOWN REGULARITIES---#\n",
    "remove = []\n",
    "rank = 1\n",
    "\n",
    "for verb in conjugations:\n",
    "    if conjugations[verb]['regularity'] == 'x':\n",
    "        remove.append(verb)\n",
    "    else:\n",
    "        conjugations[verb]['rank'] = rank\n",
    "        rank += 1\n",
    "\n",
    "print(f\"{len(conjugations)} -> {len(conjugations) - len(remove)}\")\n",
    "\n",
    "for verb in remove:\n",
    "    conjugations.pop[verb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---CREATE INTERMEDIATE CHECKPOINT FILE AS CONTINGENCY IN CASE OF KERNAL TIMEOUT---#\n",
    "with open(os.path.join(data_dir, 'conjugations_portuguese_intermediate.json'), \"w\", encoding = 'utf8') as file:\n",
    "    json.dump(conjugations, file, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SET INDEX VARIABLE TO 1 BY DEFAULT---#\n",
    "i = 669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---ADD TRANSLATIONS---#\n",
    "for verb in conjugations:\n",
    "\n",
    "    if conjugations[verb]['rank'] > i - 1 and conjugations[verb]['translations'] == []:\n",
    "        \n",
    "        translations = getReversoTranslations(verb)\n",
    "\n",
    "        if not translations:\n",
    "            translations = getGoogleTranslations(verb)\n",
    "            time.sleep(9)\n",
    "\n",
    "        conjugations[verb]['translations'] = translations\n",
    "\n",
    "        if conjugations[verb]['rank'] % 200 == 0:\n",
    "            with open(os.path.join(data_dir, 'conjugations_translated_italian_intermediate.json'), \"w\", encoding = 'utf8') as file:\n",
    "                json.dump(conjugations,file, indent = 4, ensure_ascii = False)\n",
    "\n",
    "        clear(wait = True), print(f\"{verb} ({i}) – complete ({round(i*100/len(conjugations), 3)}%)\")\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---REMOVE VERBS WITH NO TRANSLATIONS---#\n",
    "remove = []\n",
    "rank = 1\n",
    "\n",
    "for verb in conjugations:\n",
    "    if conjugations[verb]['translations'] == []:\n",
    "        remove.append(verb)\n",
    "    else:\n",
    "        conjugations[verb]['rank'] = rank\n",
    "        rank += 1\n",
    "\n",
    "for verb in remove:\n",
    "    conjugations.pop(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SAVE CONJUGATIONS TO JSON---#\n",
    "f = os.path.join(data_dir, 'conjugations_portuguese.json')\n",
    "with open(f, \"w\", encoding = 'utf8') as file:\n",
    "    json.dump(conjugations, file, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---PARSE INFINITIVES AND SAVE TO JSON---#\n",
    "infinitives = []\n",
    "\n",
    "for verb in conjugations:\n",
    "    infinitives.append([verb, conjugations[verb]['rank'], conjugations[verb]['regularity']])\n",
    "\n",
    "f = os.path.join(data_dir, 'infinitives_portuguese.json')\n",
    "with open(f, \"w\", encoding = 'utf8') as file:\n",
    "    json.dump(infinitives, file, indent = 4, ensure_ascii = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
