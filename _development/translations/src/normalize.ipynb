{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "import json\n",
    "import time\n",
    "import lxml\n",
    "import deepl\n",
    "import requests\n",
    "import cloudscraper\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from googletrans import Translator\n",
    "from difflib import SequenceMatcher\n",
    "from fake_useragent import UserAgent\n",
    "from IPython.display import clear_output as clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath('').replace('src', '')\n",
    "top_dir = Path(path).parent.absolute()\n",
    "conjugations_data_dir = os.path.join(top_dir, 'conjugations', 'data', 'language-specific')\n",
    "out_dir = os.path.join(path, 'out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'portuguese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(out_dir, 'graded', f'translations_{language}.json'), 'r', encoding = 'utf8') as file:\n",
    "    translations = json.loads(file.read())\n",
    "\n",
    "with open(os.path.join(conjugations_data_dir, f'conjugations_{language}.json'), 'r', encoding = 'utf8') as file:\n",
    "    conjugations = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if language == \"italian\" and 'ridefinire' in list( translations.keys() ):\n",
    "    del translations[\"ridefinire\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = { verb: {} for verb in translations }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modal_verbs = ['can', 'could', 'may', 'might', 'must', 'shall', 'should', 'will', 'would']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir will {'go': 160, 'leave': 9, 'be': 9, 'walk': 9, 'head': 9, 'run': 8, 'do': 8, 'ride': 8, 'wend': 7, 'manage': 7, 'travel': 7, 'prosper': 6, 'will': 5}\n",
      "poder can {'can': 40, 'may': 36, 'afford': 8, 'might': 8}\n",
      "poder may {'can': 40, 'may': 36, 'afford': 8, 'might': 8}\n",
      "poder might {'can': 40, 'may': 36, 'afford': 8, 'might': 8}\n",
      "saber can {'know': 160, 'have': 9, 'can': 9, 'find out': 9, 'determine something': 9, 'savvy': 8}\n",
      "dever shall {'owe': 136, 'shall': 69, 'must': 38, 'ought': 30, 'have': 16, 'need': 10, 'be obliged': 5}\n",
      "dever must {'owe': 136, 'shall': 69, 'must': 38, 'ought': 30, 'have': 16, 'need': 10, 'be obliged': 5}\n",
      "querer will {'want': 152, 'like': 32, 'love': 30, 'desire': 28, 'care': 10, 'will': 9, 'please': 9, 'wish': 9, 'be fond of': 8, 'feel like': 5, 'list': 4}\n",
      "decidir will {'decide': 160, 'resolve': 36, 'conclude': 9, 'settle': 8, 'adjudicate': 7, 'will': 6, 'award': 5, 'govern': 4, 'fix': 3, 'overrule': 2, 'find': 1, 'liquidate': 1, 'ordain': 1}\n",
      "desejar will {'desire': 72, 'wish': 72, 'want': 40, 'will': 32, 'crave': 26, 'ache': 18, 'like': 8, 'lust': 8, 'long': 7, 'require': 6, 'please': 5, 'need': 5, 'covet': 4, 'aspire': 3, 'hunger': 2, 'have an eye for': 1, 'desiderate': 1, 'list': 1, 'care': 1, 'fancy': 1}\n"
     ]
    }
   ],
   "source": [
    "modals = []\n",
    "\n",
    "for verb in translations:\n",
    "    for translation in translations[verb][\"weighted\"]:\n",
    "        if translation in modal_verbs:\n",
    "            print(verb, translation, translations[verb][\"weighted\"])\n",
    "            modals.append( (verb, translation) )\n",
    "\n",
    "for modal in modals:\n",
    "    verb, translation = modal\n",
    "    del translations[verb][\"weighted\"][translation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(infinitive):    \n",
    "    principal = translations[infinitive]['metadata']['principal']\n",
    "    check = { 'unique': [], 'duplicates': [] }\n",
    "    similar = { 'retain': [], 'discard': [] }\n",
    "\n",
    "    heaviest_verb = list(translations[infinitive]['weighted'].keys())[0]\n",
    "    heaviest_weight = translations[infinitive]['weighted'][heaviest_verb]\n",
    "        \n",
    "    if principal != heaviest_verb:\n",
    "        translations[infinitive]['weighted'][principal] = heaviest_weight + 1\n",
    "        heaviest_weight += 1\n",
    "\n",
    "    formatted = deepcopy(translations[infinitive]['weighted'])\n",
    "\n",
    "    formatted = dict(sorted(formatted.items(), key = lambda item: item[1])[::-1])\n",
    "\n",
    "    if principal != list(formatted.keys())[0]:\n",
    "        formatted = {**{principal: formatted[principal]}, **{translation: formatted[translation] for translation in formatted if translation != principal}}\n",
    "\n",
    "    for candidate in formatted:\n",
    "        for existing in check['unique']:\n",
    "            if candidate in existing or existing in candidate:\n",
    "                check['duplicates'].append(candidate)\n",
    "                break\n",
    "        if candidate not in check['duplicates']:\n",
    "            check['unique'].append(candidate)\n",
    "\n",
    "    for duplicate in check['duplicates']:\n",
    "        formatted.pop(duplicate)\n",
    "\n",
    "    for c1 in formatted:\n",
    "        if c1 not in similar['discard']:\n",
    "            for c2 in formatted:\n",
    "                if c1 != c2 and c2 not in similar['retain'] and c2 not in similar['discard']:\n",
    "                    if SequenceMatcher(None, c1, c2).ratio() > 0.75:\n",
    "                        formatted[c1] += formatted[c2]\n",
    "\n",
    "                        if formatted[c1] > heaviest_weight:\n",
    "                            principal = c1\n",
    "                            heaviest_weight = formatted[c1]\n",
    "\n",
    "                        similar['discard'].append(c2)\n",
    "\n",
    "    for similar in similar['discard']:\n",
    "        formatted.pop(similar)\n",
    "\n",
    "    formatted = dict(sorted(formatted.items(), key = lambda item: item[1])[::-1])\n",
    "\n",
    "    output[infinitive]['principal'] = principal\n",
    "    output[infinitive]['weighted'] = { translation: round(formatted[translation] / heaviest_weight, 4)  for translation in formatted }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagree = [(verb, conjugations[verb]['rank']) for verb in translations if translations[verb]['metadata']['principal'] != translations[verb]['metadata']['consensus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'out', 'corrections', f'corrections_{language}.json'), 'r', encoding = 'utf8') as file:\n",
    "    corrections = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aviar', 'dactilografar']\n"
     ]
    }
   ],
   "source": [
    "removed = [ verb[0] for verb in disagree ]\n",
    "\n",
    "for infinitive in corrections:\n",
    "\n",
    "    translations[infinitive]['metadata']['principal'] = corrections[infinitive]\n",
    "    \n",
    "    if infinitive in removed:\n",
    "        removed.remove( infinitive )\n",
    "\n",
    "print(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for verb in translations: \n",
    "    if verb not in removed:\n",
    "        normalize(verb)\n",
    "    else:\n",
    "        del output[verb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for verb in output:\n",
    "    if not len(output[verb]):\n",
    "        print(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( os.path.join( out_dir, 'normalized', f'translations_{language}.json'), 'w', encoding = 'utf-8') as file:\n",
    "    json.dump( output, file, indent = 8, ensure_ascii = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
